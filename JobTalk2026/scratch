                    <section>
                        <h4> Certificates from Convex Optimization </h4>
                        <p> Convex optimization can be used to <i>certify</i> that there is no point satisfying certain conditions, as long as those conditions.</p>
                        <p class="fragment"> If no, then the algorithm always succeeds. </p>
                    </section>
                    <section data-auto-animate>
                        <h3> Why Convex Optimization? </h3>
                        <ul>
                            <li class ="fragment"><p style="font-weight:bold; font-size:40px"> Fast, Well-Established Algorithms </p></li>
                            <li class ="fragment"><p style="font-weight:bold; font-size:40px"> Robust Theory </p></li>
                            <li class ="fragment"><p style="font-weight:bold; font-size:40px"> Global Optimality Guarantees </p></li>
                        </ul>
                        <p class="fragment" style="color:red; font-size:40px"> But not all optimization problems are convex! </p>
                    </section>
                </section>
                <section>
                    <section data-auto-animate>
                        <h3> What is Convex Optimization? </h3>
                        <p class=alignLeft> Convex geometry is the natural generalization of linear algebra that admits inequalities. </p>
                        <div  style="display:flex">
                            <div>
                                <p class="fragment alignLeft"> <b>Convex Set </b> - A set defined by a system of linear inequalities. </p>
                                <p class="fragment alignLeft"> <b>Convex Function </b> - A function which is the pointwise minimum of linear functions. </p>
                                <p class="fragment alignLeft"> <b>Convex optimization</b> - The study of minimizing convex functions on convex sets.  </p>
                            </div>
                            <img height=200px width=200px src="convex_function.png">
                        </div>


                    </section>
                    <section data-auto-animate>
                        <h3> Why Convex Optimization? </h3>
                    </section>
                    <section data-auto-animate>
                        <h4 class=alignLeft> Projection Simplicity</h4>
                        <p class=alignLeft><b> Optimization problems, even over complicated domains, often only depend on a few salient features of what you are optimizing. </b></p>
                        <p class=alignLeft> Focusing on these features make it is possible to find simpler (convex) formulations of the problem. </p>
                        <p class="alignLeft fragment"> How general is this phenomenon; can it be discovered and exploited automatically?</p>
                    </section>


                    <section data-auto-animate>
                        <h3> Hyperbolic polynomials for linear algebra<sup>1, 2</sup>  </h3>

                        <p style="font-size:30px; margin-top:200px; text-align:left">1. <i>Hyperbolic Relaxation of k-Locally Positive Semidefinite Matrices</i> - G Blekherman, S Dey, S Sun</p>
                        <p style="font-size:30px; text-align:left">2. <i> Debiasing Polynomial and Fourier Regression</i> - C Cama√±o and R Meyer</p>
                    </section>
                    <section data-auto-animate>
                        <h4> Hyperbolic polynomials </h4>
                        <ul>
                            <li> Polynomials with real rootedness properties </li>
                            <li> Arise in convex optimization, sampling theory, combinatorics </li>
                        </ul>
                    </section>
                    <section data-auto-animate>
                        <h4> Debiasing Polynomial and Fourier Regression </h4>
                        <ul>
                            <li> <b>Active sampling</b> - how do you find a polynomial approximation of a function $f$ <i>without knowing $f$ explicitly</i>?</li>
                            <li class=fragment> Given an oracle for computing $f(x)$, how do you find the best polynomial approximation of $f$ in the $L_{\mu}$ norm using as few evaluations as possible? </li>
                            <li class=fragment> A surprising algorithm: sample a random matrix $X$ from the $\mu$-unitary ensemble, compute its eigenvalues $\lambda_0, \dots, \lambda_d$, and interpolate a polynomial $\hat{p}$ so that $\hat{p}(\lambda_i) = f(\lambda_i)$ for each $i$. $\E[\hat{p}] = p^*$. </li>
                        </ul>
                    </section>
                    <section data-auto-animate>
                        <h4> Approximate PSD checking </h4>
                        <ul>
                            <li> <b>Approximate PSD checking</b> - If you know that all $k\times k$ submatrices of an $n\times n$ matrix are PSD, how far is that matrix from being PSD?</li>
                            <li class=fragment> We show that the worst case always has all equal diagonal entries and all equal off-diagonal entries for an arbitrary matrix norm distance metric using a convex relaxation from hyperbolic polynomials.</li>
                        </ul>
                    </section>
                    <section data-auto-animate>
                        <h4 class=alignLeft> An Example for Stiefel Manifold</h4>
                        <p> When is there a subspace of $\R^{n \times m}$ of dimension $k$ containing no singular matrix? </p>
                        <p> When $k \lt n-m,$ a generic such subspace has this property. </p>
                        <div style="background-color:lightgray; padding:30px;">
                            <h4 style="text-align:left;padding-left:50px"> Theorem (Adams, Lax, Phillips 1965)</h4>
                            <p class=alignLeft> A $k$ dimensional subspace of $\R^{n\times n}$ containing no nonzero singular matrix exists if and only if $k \le \rho(n)$. If $n = (2a+1)2^{c+4d}$ with $c \lt 4$, then $\rho(n)$ is the Radon-Hurwitz number
                            \[
                            \rho(n) = 2^c + 8d.
                            \]
                            </p>
                        </div>
                        <p>$\rho(n)$ is connected to representation theory of Clifford algebras, vector bundles on spheres. </p>
                    </section>
                    <section data-auto-animate>
                        <h4 class=alignLeft> Connections to Lie group theory and Topology  </h4>
                        <p> In examples where $M$ is the <b>orbit of a Lie group action </b>, and the constraints are <b>linear</b>, this is closely related to Kostant's convexity theorem.
                        </p>
                        <p class=fragment> Kostant's convexity theorem characterizes the maximizers of the Lagrangian.  </p>
                        <p class=fragment> Hidden convexity is implied if the constraints span a <b> noncrossing subspace</b> where certain generalized singular values are sufficiently generic .</p>
                    </section>

                            After making queries $x_0, \dots, x_n$, for <b>any</b> oracle responses $(f(x_i), \nabla f(x_i))_{i=0}^n$, the algorithm produces a number $\tau$ (depending on the responses) and guarantees that 
                            \[
                                \SUBOPT \le \tau.
                            \]
                            Moreover, for any sequence of queries, there exists a $L$-smooth convex function $f^*$ so that any algorithm making the same initial queries,
                            \[
                                \SUBOPT \ge \tau.
                            \]


                    <section data-auto-animate>
                        <h4 class=alignLeft> Example of Hidden Convexity</h4>
                        <div style="background-color:lightgray;padding-left:30px;padding-right:30px; padding-top:30px;">
                            <h4 style="text-align:left;padding-left:50px"> Theorem (Brickman) </h4>
                            <p>
                            $\{(x^{\intercal}A_0x, x^{\intercal}A_1x) : \|x\|=1\} \subseteq \R^2$ is convex.
                            </p>
                        </div>
                        <video controls><source src="QuadraticSphere.mp4" type="video/mp4"></video>(Brickman)  
                    </section>
                    <section data-auto-animate>
                        <h4 class=alignLeft> Example of Hidden Convexity</h4>
                        <div style="background-color:lightgray; padding:30px;">
                            <h4 style="text-align:left;padding-left:50px"> Theorem (Brickman)  </h4>
                            <p>
                            $\{(x^{\intercal}A_0x, x^{\intercal}A_1x) : \|x\|=1\} \subseteq \R^2$ is convex.
                            </p>
                        </div>
                        <br>
                        <div style="background-color:lightgray; padding:30px;" class=fragment>
                            <h4 style="text-align:left;padding-left:50px"> Corollary (Homogenized S-lemma)</h4>
                            <p>
                                Any QCQP of the form
                                \[
                                    \max \{x^{\intercal}A_0x : x^{\intercal}A_1x = c_1, x^{\intercal}A_2x = c_2\}
                                \]
                                has a tight convex relaxation.
                            </p>
                        </div>
                    </section>
                    <section>
                        <h4> First-Order Methods</h4>
                        <p> <b>Meta-goal:</b> Find a first-order method with good <b>worst-case behavior</b>.</p>
                        <p>Different choices of $h$'s lead to different convergence rates.</p>
                        <p> <b>Subquestion:</b> How can we tell if a given first-order method converges quickly?</p>
                    </section>
                    <section>
                        <h4> Worst-Case Instance Search</h4>
                        <p> We will restrict attention to convex, $L$-smooth functions. </p>
                        <p> <b> $L$-smooth </b> - gradient is $L$-Lipschitz under Euclidean distance. </b>
                        <p> 
                        Suppose that the $h_{ij}$ are <b>chosen in advance</b>; we want to find a `bad function' $f$ so that $f(x_n)$ is much larger than $f_{min}$ (relative to the initial error).
                        </p>
                        <p class="fragment">
                        Given an algorithm for choosing the $x_i$, can we find $f$ maximizing
                        \[
                            \SUBOPT = \frac{f(x_N) - f_{min}}{\|x_0 - x_{\star}\|^2}?
                        \]
                        </p>
                        <p class="fragment">
                        Yes! Using convex optimization.  (Drori and Teboulle, 2012) The resulting objective is the worst case rate of convergence for the algorithm. (Taylor, Hendrickx and Glineur, 2017)
                        </p>
                    </section>
                    <section data-auto-animate>
                        <h4> Performance Estimation Papers </h4>
                    </section>
                    <section data-auto-animate>
                        <h4> Performance Estimation Papers </h4>
                        <ul>
                            <li> <b> D. Kim and J. Fessler, "Optimized first-order methods for smooth convex minimization." Mathematical programming (2016) </b> </li>
                            <li> A. Taylor, and Y. Drori. "An optimal gradient method for smooth strongly convex minimization." Mathematical Programming (2023)</li>
                            <li> S. Das Gupta, B. Van Parys, and E. Ryu. "Branch-and-bound performance estimation programming: A unified methodology for constructing optimal optimization methods" Mathemathical Programming, (2023).</li>
                        </ul>
                    </section>
                    <section data-auto-animate>
                        <h4> Dynamically Optimal Gradient Methods </h4>
                        <p> OGM is <b> static</b> in the sense that the updates it makes are based on fixed coefficients chosen ahead of time. </p>
                        <p> Can we optimize the choice of updates <b>dynamically</b>? </p>
                    </section>
                    <section data-auto-animate>
                        <h4> Dynamically Optimal Gradient Methods </h4>
                        <p><b> Why is OGM minimax optimal? </b></p>
                        <p class=fragment> <b>Upper bound:</b> For OGM,
                        \[
                            \SUBOPT \le \tau.
                        \]
                        </p>
                        <p class=fragment>
                        <b>Lower bound: </b>
                        There is a function $f_{hard}$ so that <b>no algorithm</b> run on $f_{hard}$ can achieve $\SUBOPT \lt \tau$.
                        </p>
                    </section>
                    <section data-auto-animate>
                        <h4 class=alignLeft> From Continuity to Path-tracking Algorithms </h4>
                        <p>
                        <b>Discretized subproblem:</b> Find $D(\lambda_{t+\epsilon})$ given $D(\lambda_t)$
                        \[
                            \lambda_t := (1-t)\lambda + t\lambda_0.
                        \]
                        </p>
                        <div class="fragment">
                            <img src="D_lambda.png" width=40%>
                        </div>
                    </section>
                    <section data-auto-animate>
                        <h4 class=alignLeft> From Continuity to Path-tracking Algorithms </h4>
                        <p>
                        <b>Discretized subproblem:</b> Find $D(\lambda_{t+\epsilon})$ given $D(\lambda_t)$
                        \[
                            \lambda_t := (1-t)\lambda + t\lambda_0.
                        \]
                        </p>
                        <div style="display:flex;">
                            <img src="D_lambda.png" width=40%>
                            <img src="D_lambda'.png" width=40% style="margin-left:80px;">
                        </div>
                        <p class="fragment centered">Use local search to solve subproblem.</p>
                    </section>
                    <section data-auto-animate>
                        <h4 class=alignLeft> From Continuity to Path-tracking Algorithms </h4>
                        <p> Restrict to when $M$ is a Riemannian manifold, and $f$ is smooth.</p>
                        <ul> 
                            <li> <b>Riemannian gradient descent</b> is a local search procedure which converges to $D(\lambda_{t+\epsilon})$ <b> as long as we start close enough to $D(\lambda_{t+\epsilon})$.</b></li>
                            <br>
                            <li> Can control the basin of convergence in terms of the Riemannian gradient and Hessian of $\L(\lambda_{t+\epsilon}, x)$. </li>
                        </ul>
                    </section>

                    <section data-auto-animate>
                        <h4>Example Reformulation (Trust Region Problem)</h4>
                        <p> Problem </p>
                        <table>
                            <th></th>
                            <tr> <td> $\min_x$ </td> <td> $x^{\intercal}Ax + 2b^{\intercal}x + c$ </td> </tr>
                            <tr> <td> subject to </td> <td> $\|x\|^2=1, x\in \R^n$ </td> </tr>
                        </table>
                        <p>for a matrix $A \in \R^{n \times n}$, $b \in \R^n$. </p>
                        <p> Used in <b>trust region methods</b>, modeling <b>ill-conditioned linear systems</b>. </p>
                        <p> Neither the objective nor the constraint are convex. </p>
                    </section>
                    <section data-auto-animate>
                        <h4>Example Reformulation (Trust Region Problem)</h4>
                        <p> <b> Reformulation (Step 1):</b> Linearize </p>
                        <table>
                            <th></th>
                            <tr> <td> $\min_x$ </td> <td> $\tr\left[\begin{pmatrix}c & b^{\intercal}\\ b & A\end{pmatrix}X\right]$ </td> </tr>
                            <tr> <td> subject to </td> <td> $\tr(X) = 2$ </td> </tr>
                            <tr> <td> </td> <td> $X \equiv \begin{pmatrix} 1 & x^{\intercal}\\ x & xx^{\intercal}\end{pmatrix}$ </td> </tr>
                        </table>
                    </section>
                    <section data-auto-animate>
                        <h4>Example Reformulation (Trust Region Problem)</h4>
                        <p> <b> Reformulation (Step 2):</b> Relax </p>
                        <table>
                            <th></th>
                            <tr> <td> $\min_X$ </td> <td> $\tr\left[\begin{pmatrix}c & b^{\intercal}\\ b & A\end{pmatrix} X\right]$ </td> </tr>
                            <tr> <td> subject to </td> <td> $\tr(X)=2, X_{11} = 1$</td></tr>
                            <tr> <td></td><td> $X\succeq 0$ </td> </tr>
                        </table>
                        <p> This is <span style="color:var(--pastel-blue);"> convex</span>. </p>
                        <p> Easy to see $\begin{pmatrix} 1 & x^{\intercal} \\ x & xx^{\intercal}\end{pmatrix}$ are feasible for this problem. </p>
                        <p class=fragment> Can be shown is equivalent to the original problem. </p>
                    </section>
                    <section>
                        <h4> More general First-Order Methods </h4>
                    </section>
                    <section>
                        <h4> First-Order Methods </h4>
                        <p> <b>Goal:</b> Minimize functions $f : \R^d \rightarrow \R$. </p>
                        <p class=fragment> <b> Input: </b> A black box that outputs the values $f(x)$ and $\nabla f(x)$ at points of our choosing. </p>
                        <p class=fragment> <b> First-order methods:</b> Algorithm for choosing query points $x_0, \dots, x_N$. </p>
                        <img src="fom.png" height=200px/>
                    </section>
                    <section data-auto-animate>
                        <h4> First-Order Methods</h4>
                        <ul>
                            <li> D. Kim and J. Fessler, "Optimized first-order methods for smooth convex minimization." Mathematical Programming (2016) </li>
                            <li> A. Taylor, and Y. Drori. "An optimal gradient method for smooth strongly convex minimization." Mathematical Programming (2023)</li>
                            <li> S. Das Gupta, B. Van Parys, and E. Ryu. "Branch-and-bound performance estimation programming: A unified methodology for constructing optimal optimization methods" Mathematical Programming, (2023).</li>
                        </ul>
                        <!--TODO: others -->
                        <!--TODO: citation consistency -->
                    </section>
                    <section data-auto-animate>
                        <h4> First-Order Methods</h4>
                        <ul>
                            <li> <b>D. Kim and J. Fessler, "Optimized first-order methods for smooth convex minimization." Mathematical Programming (2016)</b> </li>
                            <li> A. Taylor, and Y. Drori. "An optimal gradient method for smooth strongly convex minimization." Mathematical Programming (2023)</li>
                            <li> S. Das Gupta, B. Van Parys, and E. Ryu. "Branch-and-bound performance estimation programming: A unified methodology for constructing optimal optimization methods" Mathematical Programming, (2023).</li>
                        </ul>
                        <!--TODO: others -->
                        <!--TODO: citation consistency -->
                    </section>
                    <section>
                        <h4> Optimized Gradient Method </h4>
                        <p> Introduce an <b>auxiliary vector </b> $z_i \in \R^d$. </p>
                        <p> OGM defines a sequence of scalars: $s_i, \theta_i$ for each iteration. </p>
                        <p>
                            \[
                                x_i = \theta_i \left(x_{i-1} - \frac{1}{L}\nabla f(x_{i-1})\right) + (1-\theta_i)z_{i-1}
                            \]
                            \[
                                z_i = z_{i-1} - s_i\nabla f(x_i).
                            \]
                        </p>
                        <p> How do we analyze such a method? </p>
                    </section>
                    <section data-auto-animate>
                        <h4> Two Questions </h4>
                        <p> What is left to do beyond finding a minimax optimal algorithm? </p>
                        <ul>
                            <li> Can we get good (possibly nonoptimal) convergence <b> without using extra memory </b>.</li>
                            <br>
                            <li> Can we get stronger (better than minimax optimal) convergence, using <b> additional memory </b>.</li>
                        </ul>
                    </section>
                    <section data-auto-animate>
                        <h4> Long Step gradient methods</h4>
                    </section>
                    <section>
                        <h4> Performance Estimation Problems </h4>
                        <p> OGM satisfies the following minimax optimality guarantee its final suboptimality is at most:</p>
                        <table>
                            <th></th>
                            <tr style="border-bottom:none;"> <td> <p>$\tau = \min_{\text{Alg}}$</p></td>
                                    <td> <p>$\max_f$</p> </td> <td> <p>$\SUBOPT(\text{Alg}, f)$</p> </td> </tr>
                            <tr> <td></td> <td> <p>s.t.</p> </td> <td> <p>$f$ is $L$-smooth and convex.</p> </td> </tr>
                        </table>
                        <p>That is, no other algorithm can have a better bound on its final suboptimality.</p>
                    </section>


                    <section data-auto-animate>
                        <h4 class=alignLeft> An Example for Grassmannians</h4>
                        <p class=alignLeft> Real Grassmannian - orthogonal projections</p>
                        <p class=alignLeft> \[\Gr^{n,m} = \{X \in \R^{n\times n}_{sym} : X^2 = X, \tr(X) = m\}\]</p>
                        <div style="background-color:lightgray; padding:30px;">
                            <h4 style="text-align:left"> Theorem (CDR<span style="color:var(--pastel-blue)">S</span> 2025)</h4>
                            <p class=alignLeft> If $A_0, \dots, A_k$ span a linear subspace of $\R^{n\times n}_{sym}$ containing no nonzero matrix with a repeated eigenvalue amongst its $m$ largest ones, then 
                           \[ \max \{\langle A_0, X\rangle : \langle A_1, X\rangle = c_1, \dots, \langle A_k, X\rangle = c_k, X \in \Gr^{n,m} \}=\] </p>
                            <p style="margin-left:-20px;">\[ \max \{\langle A_0, X\rangle : \langle A_1, X\rangle = c_1, \dots, \langle A_k, X\rangle = c_k, X \in \color{red}{\conv}(\Gr^{n,m})\}.\] </p>
                        </div>
                        <p>In the case $m = 1$, optimization over $\Gr^{n,m}$ corresponds to QCQPs.</p>
                    </section>
                    <section data-auto-animate>
                        <h4> Attitude Estimation (Linearized Equivalent)</h4>
                        <p> <b> Model: </b> </p>
                        <table>
                            <tr> <td> $\min_X$ </td> <td> $\tr(B^{\intercal}A X)$ </td> </tr>
                            <tr> <td> s.t. </td> <td> $\tr(I - X_0^{\intercal}X) \le \epsilon$ </td> </tr>
                            <tr> <td> </td> <td> $X \in \SO(n)$ </td> </tr>
                        </table>
                        <p>$A$ and $B$ represent the observed/stored star locations. </p><p>$X_0$ is estimated rotation matrix. </p>
                    </section>
                    <section  data-auto-animate>
                        <h4> Subgame Perfect </h4>
                        <div style="background-color:lightgray; padding:30px;">
                            <h4 style="text-align:left;"> Subgame Perfect </h4>
                            <p class=alignLeft>
                            An algorithm is <b>subgame perfect</b> if <span class=fragment>for <b>any</b> first order history $\mathcal{H} = (x_i, f(x_i), \nabla f(x_i))_{i=0}^n$, it guarantees $\SUBOPT \le \tau$, where</span>
                                <table class=fragment>
                                    <tr style="border-bottom:none;"> <td> <p>$\tau(\mathcal{H}) = \min_{\text{Alg} \in A(\mathcal{H})}$</p></td>
                                        <td> <p>$\max_{f \in F(\mathcal{H})}$</p> </td> <td> <p>$\SUBOPT(\text{Alg}, f)$</p> </td> </tr>
                                    <tr> <td></td> <td> <p>s.t.</p> </td> <td> <p>$f$ is $L$-smooth and convex.</p> </td> </tr>
                                </table>
                        </div>
                        <div class=fragment>
                        <p> Here, $A(\mathcal{H})$ are the <b> algorithms consistent with $\mathcal{H}$</b></p>
                        <p> $F(\mathcal{H})$ are the <b> $L$-smooth convex functions consistent with $\mathcal{H}$</b></p>
                        </div>
                    </section>
                    <section data-auto-animate>
                        <h4> Dynamically Optimal Gradient Methods </h4>
                    </section>
                    <section data-auto-animate>
                        <h4> Dynamically Optimal Gradient Methods </h4>
                        <p> Suppose we are optimizing a fixed function $f$.</p>
                        <p class=fragment>
                            After seeing $f(x_0), \nabla f(x_0)$, and $f(x_1), \nabla f(x_1)$, a better bound on $\SUBOPT$ may be possible than before seeing these gradients.
                        </p>
                    </section>
                    <section data-auto-animate>
                        <h4> Deficiencies of Minimax Optimality </h4>
                        <img src="quadratic_grads.png" height=400px>
                        <p> Given these two gradients, curvature bound on $f$ implies that $x=0$ is a minimizer. </p>
                        <p class=fragment> Still the function $\frac{L}{2}x^2$ is worst case for earlier minimax optimal first-order methods! </p>
                    </section>
                    <section data-auto-animate>
                        <h4> Deficiencies of Minimax Optimality </h4>
                        <p> Minimax optimal algorithms can fail to be optimal <b> among algorithms that have seen some number of oracle responses.</b></p>
                        <p> Use ideas from <b>game theory</b> to address this gap.</p>
                    </section>
                    <section>
                        <h4> Subgame Perfect Equilibrium </h4>
                        <p> How do we achieve subgame perfect equilibrium? </p>
                        <p> A version of the suboptimality optimization problem: </p>
                        <p> Here, $\SUBOPT'$ is a version of $\SUBOPT.$</p>
                        <p class=fragment> We can <b>reformulate</b> this as a second order cone program. </p>
                    </section>
                    <section>
                        <h4> The Subgame Perfect Gradient Method </h4>
                        <img src="medAccur_rand.png"/>
                    </section>

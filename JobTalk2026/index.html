<!doctype html>
<html lang="en">

	<head>
		<meta charset="utf-8">

		<title> Algorithm Design via Convex Optimization </title>

		<meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no">

		<link rel="stylesheet" href="reveal.css">
		<link rel="stylesheet" href="style.css">
		<link rel="stylesheet" href="solarized.css" id="theme">
        <style>
            li {font-size: 30px}
            .alignLeft {text-align:left;}
        </style>
	</head>

	<body>

		<div class="reveal">

			<div class="slides">

                <section>
                    <h3> Algorithm Design via </h3>
                    <h3> Convex Optimization </h3>
                    <div>
                        <!--<img src="sphere_proj.png" height="300" width="400" />-->
                    </div>
                    <div style="display:flex">
                        <p style="font-size:30px; text-align:center; flex:50%; padding-top:25px"> Kevin Shu </p> 
                        <div  style="flex:50%">
                        <img src="caltech.png" width=200px />
                        </div>
                    </div>
                </section>
                <section>
                    <section>
                        <h4> Optimization is Everywhere </h4>
                        <div style="display:flex">
                            <div style="flex:1; width:30%">
                                <h5> Robotics </h5>
                                <img src ="slam.png" height=200px>
                                <p class=centered style="font-size:20px; padding-left:10px">
                                    Rosen et al. 2021.
                                </p>
                            </div>
                            <div style="flex:1; width:30%">
                                <h5> Materials </h5>
                                <img src ="metamaterial.png" height = 200px>
                                <p class=centered style="font-size:20px; padding-left:10px">
                                 Serles et al. 2025.
                                </p>
                            </div>
                            <div style="flex:1; width:30%">
                                <h5> Machine Learning </h5>
                                <img src ="chatgpt.png" style="box-shadow: 0px 0px 30px #ddd; margin-top:50px;" height=150px>
                            </div>
                        </div>
                    </section>
                    <section>
                        <h4> Issues with Optimization </h4>
                        <div style="display:flex">
                            <img src="self_driving.png" style="flex:1; width:30%; padding-right:20px;">
                            <img src="ai_hallucination.png" style="flex:1; width:30%">
                        </div>
                    </section>
                    <section>
                        <h4> Desiderata for Optimizers </h4>
                        <ul>
                            <li style="margin-top:20px;"> Computationally efficient </li>
                            <!--ferrari-->
                            <li style="margin-top:20px;"> Reliable </li>
                            <!--subaru-->
                            <li style="margin-top:20px;"> Expressive </li>
                            <!--car with face-->
                            <li class=fragment style="margin-top:20px;color:var(--pastel-blue)"> Globally optimal</li>
                        </ul>
                    </section>
                     <section>
                        <h3> What is Convex Optimization? </h3>
                        <table>
                            <tr> <td><p><b>Convex Set</b> - For any $x, y \in C$, and $t \in [0,1]$, \[tx + (1-t)y \in C.\]</p></td>
                                <td><img src="convex_set.png" height=150px /></td></tr>
                            <tr> <td><p><b>Convex Function</b> - For any $x, y \in \R^d$, and $t \in [0,1]$, \[ f(tx + (1-t)y) \le tf(x) + (1-t)f(y).  \] </p></td>
                                <td><img src="convex_function2.png" height=150px /></td></tr>
                            <tr><td> <p class="alignLeft"> <b>Convex Program</b> - Minimize a convex function on a convex set. </p></td></tr>
                        </table>
                    </section>
                    <section>
                        <h3> What is Convex Optimization? </h3>
                        <div  style="display:flex">
                            <div style="margin:20px;flex:30%;">
                                <p style="text-align:center"> Linear Programs </p>
                                <img src="linear_programming.svg" height=150px/>
                                <table style="font-size:30px">
                                    <tr><td> $\min$ </td><td> $c^{\intercal} x$</td></tr>
                                    <tr><td> s.t. </td><td> $Ax = b$</td></tr>
                                    <tr><td> </td><td> $x \in \R^n_{\ge 0}$</td></tr>
                                </table>
                            </div>
                            <div style="margin:20px;flex:30%;">
                                <p style="text-align:center"> Conical Programs </p>
                                <img src="conical.png" height=150px/>
                                <table style="font-size:30px">
                                    <tr><td> $\min$ </td><td> $c^{\intercal} x$</td></tr>
                                    <tr><td> s.t. </td><td> $Ax = b$</td></tr>
                                    <tr><td> </td><td> $x \in K$</td></tr>
                                </table>
                                <p> e.g. $K$ is PSD cone.</p>
                            </div>
                            <div style="margin:20px;flex:30%;">
                                <p style="text-align:center"> Regression </p>
                                <img src="regressoin.png" height=150px/>
                                <table style="font-size:30px">
                                    <tr><td> $\min$ </td><td> $\|Ax - b\|_p$</td></tr>
                                    <tr><td> s.t. </td><td> $x \in \R^n$</td></tr>
                                </table>
                            </div>
                        </div>
                    </section>
                    <section>
                        <h4> Why Convex Optimization? </h4>
                        <ul style="color:var(--pastel-green)">
                            <li> Computationally efficient </li>
                            <li> Reliable </li>
                            <li> Expressive </li>
                            <li> Globally optimal </li>
                        </ul>
                        <p class="fragment" style="color:var(--pastel-red); font-size:30px; text-align:center"> But not all optimization problems are convex! </p>
                    </section>
                    <section data-auto-animate>
                        <h4>Convex Reformulations</h4>
                        <p> We want to solve some problem in engineering or science. </p>
                            <img height=300px src="landscape.png"/>
                    </section>
                    <section data-auto-animate>
                        <h4>Convex Reformulations</h4>
                        <p> We want to solve some problem in engineering or science. </p>
                        <div style="display:flex;">
                            <img height=300px src="landscape.png"/>
                            <p style="font-size:50px;margin-top:100px;">&#8594;</p>
                            <img height=300px src="landscape_convexified.png"/>
                        </div>
                    </section>
                    <section>
                        <h4> Motivating Example: Attitude Estimation </h4>
                        <p> Probes in deep space need to estimate their orientation.<sup>1</sup> </p>
                        <img height=300px src="sattelite_image.webp"/>
                        <p class=fragment> Two data sources: <b>positions</b> of distant stars and accelerometer <b> estimate </b>. </p>
                        <p class=caption style="margin-top:50px;">1. Wahba, Grace. "A least squares estimate of satellite attitude." (1965).</p>
                    </section>
                    <section>
                        <h4> Attitude Estimation </h4>
                        <p> <b> Goal: </b> Find a rotation satisfying two conditions: </p>
                        <ol>
                            <li> Transforms an internal star map to observed locations of the stars. </li>
                            <li> Is not too far from some the estimate from the accelerometer. </li>
                        </ol>
                        <p class=fragment> The set of rotations is called the <b> special orthogonal group </b> $\SO(3)$. 
                        \[
                        \SO(n) = \{X \in \R^{n \times n} : X^{\intercal}X = I, \det(X) = 1\}.
                        \]
                        </p>
                    </section>
                    <section data-auto-animate>
                        <h4> Attitude Estimation </h4>
                        <p> <b> Model: </b> </p>
                        <table>
                            <tr> <td> $\min_X$ </td> <td> $\|AX - B\|_F^2$ </td> <td><p style="color:var(--pastel-blue)">Star map error</p></td> </tr>
                            <tr> <td> s.t. </td> <td> $\|X - X_0\|_F^2 \le \epsilon$ </td> <td><p style="color:var(--pastel-blue)">Accelerometer estimate</p></td> </tr>
                            <tr> <td> </td> <td> $X \in \SO(n)$ </td><td> <p style="color:var(--pastel-blue)">Rotation constraint</p> </td> </tr>
                        </table>
                        <p>$A, B \in \R^{d \times n}$ represent the observed/stored star locations.</p>
                        <p>$X_0 \in \R^{n \times n}$ is estimated rotation matrix.</p>
                        <p>$\|\cdot\|_F = \sqrt{\tr(X^{\intercal}X)}$ is the Frobenius norm. </p>
                    </section>
                    <section data-auto-animate>
                        <h4 class=alignLeft> Hidden Convexity</h4>
                        <div style="background-color:lightgray; padding:30px;">
                            <h4 style="text-align:left"> Theorem (R<span style="color:var(--pastel-blue)">S</span>W 2024)</h4>
                            <p class=alignLeft> If $A, B \in \R^{d\times n}$ and $X_0 \in \R^{n \times n}$ for $n > 2$, then 
                            \[ \big\{(\|AX - B\|^2, \|X - X_0\|^2) : X \in \SO(n)\big\} \subseteq \R^2\] 
                            is convex. </p>
                        </div>
                        <div style="display:flex">
                        <p> If we let $C$ be the convex set in the above theorem, then the attitude estimation problem can be represented as \[\min \{y_0 : y_1 \le \epsilon, (y_0, y_1) \in C\}.\] </p>
                        <img height=150px  src="so3_proj.png"/>
                        </div>
                    </section>
                    <section data-auto-animate>
                        <h4> Manifestations of hidden convexity in my work </h4>
                        <img src="spoke_and_hub.png"/>
                    </section>
                    <section data-auto-animate>
                        <h4> Manifestations of hidden convexity in my work </h4>
                        <img src="spoke_and_hub2.png"/>
                    </section>
                </section>
                <section data-auto-animate>
                    <h4> Outline of the Talk </h4>
                    <ol>
                        <li> Introduction </li>
                        <br>
                        <li> Automatic Design of Algorithms via Optimization </li>
                        <ul>
                            <li> First-Order Methods </li>
                            <li> Long Step Gradient Descent</li>
                            <li> Subgame Perfect Gradient Method</li>
                        </ul>
                        <br>
                        <li> Other Work </li>
                        <ul>
                            <li> Hidden Convexity and Topology</li>
                            <li> Log-Concave polynomials</li>
                        </ul>
                        <br>
                        <li> Conclusions and Future Work</li>
                    </ol>
                </section>
                <section>
                    <section data-auto-animate>
                        <h3> Automatic Design of Algorithms via Optimization<sup style="font-size:35px">1, 2, 3</sup>  </h3>

                        <p style="font-size:30px; margin-top:200px; text-align:left">1. <i>Accelerated objective gap and gradient norm convergence for gradient descent via long steps (INFORMS JOO, 2024)</i></p>
                        <p style="font-size:30px; text-align:left">2. <i>Composing optimized stepsize schedules for gradient descent</i>(MOR, 2025)</p>
                        <p style="font-size:30px; text-align:left">3. <i>Beyond Minimax Optimality: A Subgame Perfect Gradient Method (In revision at Math Prog, 2025)</i></p>
                        <p><b>All joint with Alex Wang and Ben Grimmer</b></p>
                    </section>
                    <section data-auto-animate>
                        <h3> Bad Instance Search  </h3>
                        <p> Proving that an algorithm works is equivalent to proving <i>non-existence</i> of a bad instance. </p>
                        <img height=200px src="algo_diagram.png"/>
                        <p class=fragment> Heuristic search for bad instances insufficient - can convex optimization be used to prove algorithms correct? </p>
                        <p class=fragment> We will demonstrate this methodology <b>in the context of first-order optimization algorithms</b>.</p>
                    </section>
                    <section>
                        <h4> First-Order Methods</h4>
                        <div style="display:flex">
                            <div> 
                                <p> <b>Goal:</b> Minimize function $f : \R^d \rightarrow \R$. </p>
                                <p class=fragment data-fragment-index=1 > <b> Input: </b> A black box that outputs the values $f(x)$ and $\nabla f(x)$ at points of our choosing. </p>
                                <div class=fragment data-fragment-index=3 >
                                    <p> <b> First-order methods:</b> Algorithm for choosing query points $x_0, \dots, x_N$. </p>
                                    <p> <b> Examples:</b> Gradient Descent, ADAM, BFGS, ... </b>
                                </div>
                            </div>
                            <div class="r-stack">
                              <img
                                src="dotted_plot1.png"
                                width="450"
                                height="300"
                              />
                              <img
                                  class="fragment"
                                  data-fragment-index=2
                                class="fragment fade-out"
                                src="dotted_plot2.png"
                                width="450"
                                height="300"
                              />
                              <img
                                class="fragment"
                                  data-fragment-index=5
                                src="dotted_plot3.png"
                                width="450"
                                height="300"
                              />
                              <img
                                class="fragment"
                                  data-fragment-index=6
                                src="dotted_plot4.png"
                                width="450"
                                height="300"
                              />
                            </div>
                        </div>
                        <p class=fragment> We will be focused on analyzing performance on <b> convex functions with $L$-Lipschitz gradients ($L$-smooth convex functions).</b></p>
                    </section>
                    <section>
                        <h4> Bad Instance Search </h4>
                        <div style="padding:20px; background-color:black">
                        <p style="color:white"> <b> Find a function $f$ on the algorithm achieves its worst performance. </b></p>
                        </div>
                        <div class=fragment>
                        <p> Formally, define error metric </p>
                        <p>

                        \[
                            \SUBOPT_N(\text{Alg},f) = \frac{f(x_N) - f_{min}}{\|x_0 - x_{\star}\|^2}.
                        \]
                        </p>
                        </div>
                        <div class=fragment>
                        <p> Worst-case instance search for a fixed algorithm Alg </p>
                        <table>
                            <th></th>
                            <tr style="border-bottom:none;"> <td> $\max_f$ </td> <td> $\SUBOPT_N(\text{Alg},f)$ </td> </tr>
                            <tr> <td> s.t. </td> <td> $f$ is $L$-smooth and convex. </td> </tr>
                        </table>
                        </div>
                    </section>
                    <section>
                        <h4> Bad Instance Search </h4>
                        <div>
                        <p> Worst-case instance search for a fixed algorithm Alg </p>
                        <table>
                            <th></th>
                            <tr style="border-bottom:none;"> <td> $\max_f$ </td> <td> $\SUBOPT(\text{Alg},f)$ </td> </tr>
                            <tr> <td> s.t. </td> <td> $f$ is $L$-smooth and convex. </td> </tr>
                        </table>
                        </div>
                        <div class=fragment>
                            <p>The worst case is piecewise quadratic (Taylor, Hendrickx and Glineur 2017). Can use <b> semidefinite programming </b> to find the worst case function.</p>
                        </div>
                        <p class=fragment> We give explicit dual solutions to this convex program to prove convergence rates.</p>
                    </section>
                    <section data-auto-animate>
                        <h4> New First-Order Methods: </h4>
                        <h4> Gradient Descent  </h4>
                    </section>
                    <section data-auto-animate>
                        <h4> Accelerating Gradient Descent </h4>
                        <p>Gradient descent sets  \[x_i = x_{i-1} - h_i\nabla f(x_{i-1})\]
                        for a choice of step sizes $h_0, \dots, h_N$.</p>
                        <p class=fragment>Standard step size choice is $h_i = \frac{1}{L}$, converging at a rate of $O(1/n)$.</p>
                        <div class=fragment>
                        <p> Much work treats constant step size case, all converging at $O(1/n)$ rate.</p>
                        <ul>
                            <li> Y. Drori and M. Teboulle. (2014)</li>
                            <li> T. Rotaru, F. Glineur, and P. Patrinos. (2024).</li>
                            <li> J. Kim. (2024)</li>
                        </ul>
                        </div>
                    </section>
                    <section data-auto-animate>
                        <h4>Our step sizes</h4>
                        <p> Can gradient descent be asymptotically faster on convex functions just by tuning the step sizes? </p>
                        <div class=fragment>
                        <p>  <span style="color:red">Yes! With nonmonotonic, unbounded size, and typically asymmetric step sizes. </span></p>
                        <p> First (contemporaneous) work: (Altschuler and Parrilo 2024) and (G<span style="color:var(--pastel-blue)">S</span>W 2024).</p>
                        </div>
                    </section>
                    <section data-auto-animate>
                        <h4>Our step sizes</h4>

                        <p> Our latest result: </p>
                        <div>
                            <div style="display:flex">
                                <div style="flex:1">

                                    <div style="background-color:lightgray;padding:30px;">
                                        <h4 style="text-align:left;"> Theorem (G<span style="color:var(--pastel-blue)">S</span>W 2024)<sup>1</sup> </h4>
                                        <p>
                                            There is a dynamic program for finding an optimized<sup>*</sup> sequence of $n$ step sizes achieving a worst case rate of convergence of $O(1/n^{1.27})$. 
                                        </p>
                                    </div>
                                </div>
                                <div style="flex:1">
                                    <img src="n50.png">
                                </div>
                            </div>
                            <p class=fragment> <sup>*</sup>conjectured to be <b>minimax optimal</b> amongst gradient descent methods. </p>
                            <p style="font-size:20px;"> <sup>1</sup>Simultaneous with Jiang and Zhang. </p>
                        </div>
                    </section>
                    <section>
                        <h4>Our step sizes - Intuition</h4>
                        <p> Two extreme functions: </p>
                        <div style="display:flex">
                            <div style="flex:1">
                                <img  height=200px src="quadratic.png"/>
                                <p style="text-align:center; font-size:20px">$f(x) = \frac{L}{2}x^2$</p>
                            </div>
                            <div style="flex:1">
                                <img height=200px src="huber.png"/>
                                <p style="text-align:center; font-size:20px">$f(x) = \begin{cases} L\left(|x|-\frac{1}{2}\right) \text{ if }|x| > 1\\ \frac{L}{2}x^2 \text{ otherwise}\end{cases}$</p>
                            </div>
                        </div>
                        <p> Optimal step sizes balance performance on these two functions in a recursive fashion. </p>
                    </section>
                    <section>
                        <h4> Minimax Optimality </h4>
                        <p> A first-order algorithm is minimax optimal for some class of algorithms $\mathcal{A}$ if its worst case suboptimality is minimized in that class, i.e. equal to </p>
                        <table>
                            <th></th>
                            <tr style="border-bottom:none;"> <td> <p>$\min_{\text{Alg} \in \mathcal{A}}$</p></td>
                                    <td> <p>$\max_f$</p> </td> <td> <p>$\SUBOPT_N(\text{Alg}, f)$</p> </td> </tr>
                            <tr> <td></td> <td> <p>s.t.</p> </td> <td> <p>$f$ is $L$-smooth and convex.</p> </td> </tr>
                        </table>
                        <p class=fragment> We conjecture the step sizes discovered in (G<span style="color:var(--pastel-blue);">S</span>W 2024) are minimax optimal amongst all gradient descent methods. </p>
                        <p class=fragment> Earlier work in (Kim and Fessler 2016) are minimax optimal amongst all first-order methods, achieving $O(1/n^2)$ convergence. </p>
                        <p class=fragment> Is minimax optimality the best guarantee a first-order method can provide? </p>
                    </section>
                    <section data-auto-animate>
                        <h4> New First-Order Methods: </h4>
                        <h4> Subgame Perfect Algorithms  </h4>
                    </section>
                    <section data-auto-animate>
                        <h4> Optimization as a Game</h4>
                        <p> Model an <i>adversarial first-order oracle</i> as an opponent in a zero-sum game. </p>
                        <div style="display:flex"> 
                            <ul>
                                <li> Two players: <span class=optimizer>Optimizer</span> and <span class=oracle>Oracle</span>. </li>
                                <li class=fragment data-fragment-index=2> Each <i>iteration</i> of algorithm is a round. </li>
                                <li class=fragment data-fragment-index=3> <span class=optimizer>Optimizer</span> moves by choosing query. </li>
                                <li class=fragment data-fragment-index=3> <span class=oracle>Oracle</span> moves by choosing response. </li>
                                <li class=fragment> An <i>algorithm</i> is <span class=optimizer>Optimizer</span>'s strategy .</li>
                                <li class=fragment> <span class=optimizer>Optimizer</span>'s final cost is $\SUBOPT_N$. </li>
                            </ul>
                            <div class="r-stack">
                              <img
                                src="move1.png"
                                class=fragment
                                data-fragment-index=3
                                width="300"
                                height="300"
                              />
                              <img
                                  class="fragment"
                                  data-fragment-index=4
                                class="fragment fade-out"
                                src="move_2.png"
                                width="300"
                                height="300"
                              />
                              <img
                                class="fragment"
                                  data-fragment-index=5
                                src="move_2_prime.png"
                                width="300"
                                height="300"
                              />
                            </div>
                        </div>
                    </section>
                    <section data-auto-animate>
                        <h4> Optimal Play </h4>
                        <p> <b> Nash equilibrium</b> - Strategies so that <span class=optimizer>Optimizer</span> and <span class=oracle>Oracle</span> can produce matching bounds on $\SUBOPT_N$.</p>
                        <p> <span class=optimizer>Optimizer</span>'s optimal strategy: Minimax optimal algorithm. </p>
                        <p> <span class=oracle>Oracle</span>'s optimal strategy: worst-case function with performance lower bound. </p>
                        <p class=fragment> <b>Issue:</b> Nash equilibrium guarantee does not change if <span class=oracle>Oracle</span> plays <i>suboptimally,</i> i.e. the function is not worst case.</p>
                    </section>
                    <section data-auto-animate>
                        <h4> Suboptimal Play </h4>
                        <p> Are there easier functions? </p>
                        <div>
                          <img
                            src="move_2.png"
                            width="200"
                            height="200"
                          />
                          <p class="centered caption"> $f = \frac{L}{2}x^2$ </p>
                        </div>
                        <p> Given $\nabla f(x_0) = Lx_0$ and $\nabla f(x_1) = Lx_1$ with $x_0 \lt 0 \lt x_1$, then curvature bounds imply that $x = 0$ is a minimizer.</p>
                        <p class=fragment><b> Existing minimax optimal algorithms have this as their worst case!</b></p>
                    </section>
                    <section data-auto-animate>
                        <h4> Subgame Perfect Equilibrium </h4>
                        <div>
                            <p> The game state after playing some number of rounds defines a <i>subgame</i>.</p>
                            <p> Subgames specified by <i>first-order history</i> $\mathcal{H}_n = (x_i, f(x_i), \nabla f(x_i))_{i=0}^n$.</p>
                            <p> <b>Subgame perfect equilibrium -</b> Stategies so that in every subgame, the players are in Nash equilibrium. </p>
                        </div>
                        <div class="r-stack">
                          <img
                            src="game_tree.png"
                            width="600"
                            height="400"
                          />
                          <img
                              class="fragment"
                              data-fragment-index=2
                            class="fragment fade-out"
                            src="game_tree_optimal.png"
                            width="600"
                            height="400"
                          />
                        </div>
                        <p class=fragment data-fragment-index=2> Nash equilibrium path </p>
                    </section>
                    <section  data-auto-animate>
                        <h4> Subgame Perfect </h4>
                        <div style="background-color:lightgray; padding:30px;">
                            <h4 style="text-align:left;"> Definition - Subgame Perfect </h4>
                            <p class=alignLeft>
                            An $N$-step first order method is <b>subgame perfect</b> if for any $0 \le n \le N$, <span class=fragment>for <b>any</b> first order history $\mathcal{H}_n = (x_i, f(x_i), \nabla f(x_i))_{i=0}^n$,</span>
                            <div class=fragment>
                            <p>
                            it guarantees $\SUBOPT_N \le \tau(\mathcal{H}_n)$, where</p>
                                <table>
                                    <tr style="border-bottom:none;"> <td> <p>$\tau(\mathcal{H}_n) = \min_{\text{Alg} \in A(\mathcal{H}_n)}$</p></td>
                                        <td> <p>$\max_{f \in F(\mathcal{H}_n)}$</p> </td> <td> <p>$\SUBOPT(\text{Alg}, f)$</p> </td> </tr>
                                </table>
                            </div>
                        </div>
                        <div class=fragment>
                        <p> Here, $A(\mathcal{H}_n)$ are the <b> algorithms consistent with $\mathcal{H}_n.$</b></p>
                        <p> $F(\mathcal{H}_n)$ are the <b> $L$-smooth convex functions consistent with $\mathcal{H}_n$.</b></p>
                        </div>
                    </section>
                    <section>
                        <h4> Subgame Perfect Gradient Method </h4>
                        <div style="background-color:lightgray; padding:30px;">
                            <h4 style="text-align:left;"> Theorem (G<span style="color:var(--pastel-blue)">S</span>W 2025)</h4>
                            <p class=alignLeft> There is a subgame perfect first-order method (SPGM) that runs in polynomial time per iteration. </p>
                        </div>
                    </section>
                    <section>
                        <h4> Subgame Perfect Gradient Method </h4>
                        <b> Key idea</b>
                        <p> In each iteration, solve the worst-case function optimization problem. </p>
                        <table>
                            <th></th>
                            <tr style="border-bottom:none;"> <td> $\max_f$ </td> <td> $\SUBOPT'$ </td> </tr>
                            <tr> <td> s.t. </td> <td> $f$ is $L$-smooth and convex. </td> </tr>
                            <tr> <td> For each $i \lt n$, </td> <td> $f(x_i)$, $\nabla f(x_i)$ are fixed. </td> </tr>
                        </table>
                        <p> $\SUBOPT'$ is a slight modification of $\SUBOPT$. </p>
                        <p class=fragment> This can be reformulated as a second order cone program and solved in $O(n^{3.5} + dn)$ time, where $n$ is the number of iterations.</p>
                    </section>
                    <section>
                        <h4> Subgame Perfect Gradient Method </h4>
                        <b> Key idea</b>
                        <p> Our next iterate is an <i>average</i> between an <i>ordinary gradient step</i> and the minimizer of a worst case function. </p>
                        <p>
                            \[
                                x_{i+1} = \theta_i \left(x_i - \frac{1}{L}\nabla f(x_i)\right) + (1-\theta_i) x_{\star}
                            \]
                            $x_{\star}$ is the minimizer of worst case $f$, and $\theta_i \in [0,1]$ depends on $f(x_{\star})$.
                        </p>
                        <div class=fragment>
                        <p>
                            This choice of iterate <i> hedges </i> between two cases:
                        </p>
                            <ul>
                                <li><p> $f$ is close to worst case - $x_{\star}$ is best next iterate.</p></li>
                                <li><p> $f$ is far from worst case - a gradient step leads to fast convergence.</p></li>
                            </ul>
                        </div>
                    </section>
                    <section>
                        <h4> Subgame Perfect Gradient Method </h4>
                        <div style="display:flex">
                            <img src="log_sum_exp_256.png" height=300px width=100px style="flex:1;padding-right:30px"/>
                            <img src="least_squares_64.png" height=300px width=100px style="flex:1" />
                        </div>
                    </section>
                    <section>
                        <h4> Summary</h4>
                        <p> Convex optimization can be used to design first-order algorithms (for convex optimization) </p>
                        <p> Subgame perfection as a notion of optimality. </p>
                    </section>
                </section>
                <section>
                    <section>
                        <h3>Other Work</h3>
                    </section>
                    <section>
                        <h4> Convex Relaxations for Manifold Optimization </h4>
                        <p style="text-align:left"> Many manifold optimization problems have <b>convex relaxations </b>. </p>
                        <div style="display:flex">
                            <div style="background-color:lightgray; padding:30px;">
                                <h4 style="text-align:left"> Examples </h4>
                                <ul >
                                    <li><p> Quadratically Constrained Quadratic Programming (QCQP)</p>
                                        <p style="font-size:20px">Combinatorics, Power Systems</p>
                                    </li>
                                    <li><p> Stiefel Manifold Optimization </p>
                                        <p style="font-size:20px">Robotics, Computer Vision</p>
                                    </li>
                                    <li><p> Inverse Eigenvalue Problems  </p>
                                        <p style="font-size:20px">Spectral Graph Theory, Network Science, Sturm-Liouville Equations </p>
                                    </li>
                                </ul>
                            </div>
                            <div>
                            <img width=300px src="rotating surface.gif"/>
                            <p style="padding-left:20px; font-size:20px;"> Boy's embedding of $\R\mathbb{P}^2$. </p>
                            </div>

                        </div>
                        <p> We give a topological framework for showing tightness of relaxations. </p>
                    </section>
                    <section>
                        <h3> Log-Concave Polynomials</h3>
                        <p> Log-Concave polynomials are fundamental in the intersection of <i> optimization </i>, <i> combinatorics </i>, and <i>Markov chain sampling algorithms </i> </p>
                        <p> Highlights from my work: </p>
                        <ul>
                            <li> <p> Connections between <i>eigenvalues of random matrices</i> and <i>active sampling for polynomial regression</i></p></li>
                            <li> <p> Solution methods for semidefinite programs with <i>sparsity constraints</i>.</p> </li>
                            <li> <p> Generalizations of linear algebraic concepts.</p> </li>
                        </ul>

                    </section>
                </section>
                <section>
                    <section>
                        <h3> Conclusions and Future Work</h3>
                    </section>
                    <section>
                        
                        <h4> Projection Simplicity </h4>
                        <p> <b>Lifting </b> approaches are central to convex optimization. <b>Extension complexity</b> quantifies this. </p>
                        <p> <b>Projection simplicity</b> - can we understand when low dimensional projections are simpler to optimize over?  </p>
                        <ul> 
                            <li> In polytope case, interesting examples coming from zonotopes. Possible connections to matroid polytopes? </li>
                        </ul>
                        <div style="display:flex;">
                            <img src="rotating surface.gif" style="flex:30%" height=150px/>
                            <p style="font-size:50px;margin-top:75px; text-align:center; flex:30%;">&#8594;</p>
                            <img height=150px  style="flex:30%;" src="so3_proj.png"/>
                        </div>
                    </section>
                    <section>
                        <h4> Algorithm Design via Convex Relaxations </h4>
                        <p> Designing algorithms requires proving that there are <b> no instances where the algorithm fails</b>. </p>
                        <p> Convex relaxations bounded the possible bad instances for first order algorithms. </p>
                        <ul> 
                            <li> Can we apply this methodology to <b>combinatorial algorithms</b> e.g. sorting networks? </li>
                        </ul>
                        <img src="algo_diagram.png" height="200px;"/>
                    </section>
                    <section>
                        <h4> References </h4>
                        <p style="font-size:20px"> First-order methods </p>
                        <ul>
                            <li class="citation"> <i>Accelerated objective gap and gradient norm convergence for gradient descent via long steps</i> - B Grimmer, <span style="color:var(--pastel-blue)">K Shu</span>, AL Wang (INFORMS JOO, 2024)</li>
                            <li class="citation"> <i>Composing optimized stepsize schedules for gradient descent</i> - B Grimmer, <span style="color:var(--pastel-blue)">K Shu</span>, AL Wang (MOR, 2025)</li>
                            <li class="citation"> <i>Beyond Minimax Optimality: A Subgame Perfect Gradient Method</i> - B Grimmer, <span style="color:var(--pastel-blue)">K Shu</span>, AL Wang (In Revision - Math Prog, 2025)</li>
                        </ul>
                        <p style="font-size:20px"> Topology </p>
                        <ul>
                            <li class="citation"> <i>Hidden convexity, optimization, and algorithms on rotation matrices</i> - A Ramachandran, <span style="color:var(--pastel-blue)">K Shu</span>, AL Wang (MOR, 2024)</li>
                            <li class="citation"> <i>Lagrangian Dual Sections: A Topological View of Hidden Convexity</i> - V Chandrasekaran, T Duff, J Rodriguez, <span style="color:var(--pastel-blue)">K Shu</span> (In Submission, 2025)</li>
                        </ul>
                        <p style="font-size:20px"> Hyperbolic Polynomials </p>
                        <ul>
                            <li class="citation"> <i> Hyperbolic Relaxation of k-Locally Positive Semidefinite Matrices</i> - G Blekherman, S Dey, <span style="color:var(--pastel-blue)">K Shu</span>, S Sun (SIOPT, 2022)</li>
                            <li class="citation"> <i> Linear Principal Minor Polynomials: Hyperbolic Determinantal Inequalities and Spectral Containment</i> - G Blekherman, M Kummer, R Sanyal, <span style="color:var(--pastel-blue)">K Shu</span>, S Sun (IMRN, 2022)</li>
                            <li class="citation"> <i> Symmetric Hyperbolic Polynomials</i> - G Blekherman, J Lindberg, <span style="color:var(--pastel-blue)">K Shu</span> (J Pure and Appl. Algebra, 2025)</li>
                        </ul>
                        <p style="font-size:20px"> Probability </p>
                        <ul>
                            <li class="citation"> <i>  Debiasing Polynomial and Fourier Regression </i> - C Camano, R Meyer, <span style="color:var(--pastel-blue)">K Shu</span>, S Sun (SOSA, 2025)</li>
                            <li class="citation"> <i>  A Semidefinite Hierarchy for the Expected Independence Number of a Random Graph </i> - D Cifuentes, <span style="color:var(--pastel-blue)">K Shu</span>, A Toriello (Opt Letters, 2025)</li>
                        </ul>
                    </section>
                    <section>
                        <h4> Conclusions </h4>
                        <p> <b>Surprising appearances of convex optimization</b></p>
                        <ul>
                            <li> Manifold Optimization </li>
                            <li> Algorithm Design </li>
                        </ul>
                        <p><b> Mathematical connections </b></p>
                        <ul style="margin-left:-75px;">
                            <li> Topology </li>
                            <li> Game Theory </li>
                        </ul>
                        <br>
                        <p style="text-align:center"><a>https://kevinshu.me</a></p>
                    </section>
                </section>
                <section>
                    <section>
                        <h3> Bonus Slides </h3>
                    </section>
                    <section>
                        <h4 style="text-align:left"> Proof of Lagrangian Dual Sections Theorem </h4>
                        <p> Restrict $D$ to the upper hemisphere to get a map of topological spaces $B^{k} \rightarrow M$. View $f$ as a map from $M$ to the convex hull of $f(M)$, denoted by $C$.</p>
                        <p> $D$ has image in $\partial C$, which is homeomorphic to a sphere $S^k$. Combining these maps, we get a map $B^k$ to $S^k$. </p>
                    </section>
                    <section>
                        <div style="background-color:lightgray; padding:30px;">
                            <h4 style="text-align:left"> Theorem (CDR<span style="color:var(--pastel-blue)">S</span> 2025)</h4>
                            <p class=alignLeft>
                                Suppose that for all $\lambda \in \R^{k+1}$, $\L(\lambda,X)$ has a unique maximizer over $x \in M$, and that $M$ is a metric space. Then the map $D(\lambda) = \argmax_{x \in M}\L(\lambda, x).$ is continuous.
                            </p>
                        </div>
                    </section>
                    <section>
                        <p> <b>Lagrangian dual sections for $\SO(n)$</b> Let $A_0, \dots, A_k \in \R^{n\times n}$. Lagrangian of 
                        \[
                        f(X) = (\langle A_0, X\rangle, \dots, \langle A_k, X\rangle)\text{ is}
                        \]
                        \[
                        \L(\lambda, X) = \langle \sum_{i=0}^k \lambda_i A_i, X\rangle.
                        \]
                        </p>
                        <p> We can change basis so that $\lambda_i A_i$ is diagonal without changing structure of optimal solutions. </p>
                        <p> If SVD of $\lambda_i A_i$ is $U\Sigma V^{\intercal}$, where <b>$\Sigma$ has distinct singular values</b> then the unique maximizer of $\L(\lambda, X)$ is given by $UDV^{\intercal}$, where $D$ is the identity or $D - 2v_{min}v_{\min}^{\intercal}$ depending on the sign of $\det(\lambda_i A_i)$. (Ky Fan, Kostant)  </p>
                    </section>
                    <section>
                        <p> 
                            <b>Von-Neumann-Wigner:</b> If $A_0, A_1 \in \R^{n\times n}$ are <b>generic</b>, then there is no nonzero matrix of the form $\lambda_0 A_0 + \lambda_1 A_1$ which has repeated singular values.
                        </p>
                        <p> 
                            This, plus a limiting argument, implies that all 2D projections of $\SO(n)$ are convex.
                        </p>
                    </section>
                    <section>
                        <h3> Performance Estimation Problems </h3>
                        <p> <b>Interpolation conditions: </b>
                        \[
                            Q_{ij} = f(x_i) - f(x_j) - \langle \nabla f(x_j), x_i - x_j \rangle - \frac{1}{2L}\|\nabla f(x_i) - \nabla f(x_j)\|^2 \ge 0.
                        \]
                        </p>
                        <p> <b>Suboptimality optimization problem</b>: let $f_i = f(x_i)$ and $\nabla f(x_i) = g_i$ and $x_i = x_0 - \sum_{j=0}^{i-1}h_{ij}\nabla f(x_i)$, then the suboptimality optimization problem is
                        \[
                        \max \{\frac{f_N - f_{\star}}{\|x_0 - x_{\star}\|^2} : \forall i, j: f_i - f_j - \langle g_i, x_i - x_j\rangle  - \frac{1}{2L}\|g_i - g_j\|^2\}.
                        \]
                        </p>
                        <p> This is a quadratic program, and its SDP relaxation is tight (as long as $d > N$). </p>
                    </section>
                    <section>
                        <h3> Performance Estimation Problems </h3>
                        <p> <b>SPGM Subproblem</b></p>
                        <table>
                            <tr> <td>$\min_{\xi \in \R, z \in \R^d}$</td><td> $\frac{L}{2\xi}\|x_0 - z\|^2$ </td></tr>
                            <tr> <td>s.t.</td><td> $f_i - \frac{1}{2L}\|g_i\|^2 - \langle g_i, x_i - \frac{1}{L}g_i \rangle$</td></tr>
                            <tr> <td></td><td style="padding-left:100px"> $+  L \langle g_i, z\rangle \le f_{n-1} - \frac{1}{2L}\|g_{n-1}\|^2 - \xi$</td></tr>
                            <tr> <td></td><td>$\xi \gt 0$</td></tr>
                        </table>
                        <p> <b>SPGM update:</b>
                        \[
                            x_{i+1} = \theta_i\left(x_i - \frac{1}{L}g_i\right) + (1-\theta_i)z_i,
                        \]
                        where $z_i$ is the optimizer from above.
                        </p>
                    </section>
                    <section>
                        <p>In the above,
                        \[
                            \theta_i = \frac{\tau_i}{\tau_i + \delta(\tau_i)},
                        \]
                        where $\delta(t) = 1+\sqrt{1+2t}$, and $\tau$ is the optimal value of the SPGM subproblem.</p>
                    </section>
                </section>
            </div>

		</div>

		<script src="reveal.js"></script>
		<script src="math.js"></script>
		<script>
			Reveal.initialize({
				history: true,
				transition: 'linear',
                slideNumber: true,

				mathjax2: {
					config: 'TeX-AMS_HTML-full',
					TeX: {
						Macros: {
							R: '\\mathbb{R}',
							SO: '\\text{SO}',
							Gr: '\\text{Gr}',
							St: '\\text{St}',
							tr: '\\text{tr}',
							E: '\\mathbb{E}',
							conv: '\\text{conv}',
							L: '\\mathcal{L}',
							SUBOPT: '\\text{SUBOPT}',
							argmax: '\\text{argmax}',
							argmin: '\\text{argmin}',
							set: [ '\\left\\{#1 \\right\\}', 2 ]
						}
					}
				},

				// There are three typesetters available
				// RevealMath.MathJax2 (default)
				// RevealMath.MathJax3
				// RevealMath.KaTeX
				//
				// More info at https://revealjs.com/math/
				plugins: [ RevealMath.MathJax2 ]
			});
            Reveal.addEventListener( 'drawCurve', function() {
                element = document.getElementById("curveDrawing");
                element.classList.add("path");
            } );
		</script>

	</body>
</html>
